{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamesruntas/SYSC4415/blob/main/SYSC4415W23_Assignment_2_(Template).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SYSC4415 - Assignment 2\n",
        "\n",
        "**TA: Fran√ßois Charih \\<francois@charih.ca\\>**\n",
        "\n",
        "**Deadline: March 19th, 2023 @ 11:59PM**\n",
        "\n",
        "## Learning objectives\n",
        "\n",
        "1. Fine-tune pre-trained CNN architectures for a custom image classification challenge.\n",
        "\n",
        "2. Evaluate the performance of machine learning models using different metrics (precision-recall curve, confusion matrices, *etc.*).\n",
        "\n",
        "3. Get hands-on experience with modern machine learning and plotting libraries.\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1. Give yourself plenty of time to complete the assignment (it could take you up to 8-10 hours if you are unfamiliar with Python and machine learning libraries). The models should not take more than 1h to fine-tune (my full notebook runs from start to end in a little under 40 minutes. Coding will be the most time-consuming. ‚ö†Ô∏è**Do not wait to the last minute.** ‚ö†Ô∏è\n",
        "\n",
        "2. You must use the prescribed methods/functions/libraries mentioned, whenever specified. The functions you need are already imported for you in the appropriate sections. You can reorganize the imports and import the full packages instead of specific functions if you so desire. I imported the necessary functions for you so that they are ready to be invoked without have to specify the full path to the functions with the dot operator (i.e. so that you invoke `function()` instead of `package.module.function()`).\n",
        "\n",
        "3. Make sure to include comments for non-trivial code. It is okay to add some code cells, if you think it will give your code better readability/structure.\n",
        "\n",
        "4. If you are unsure about something, clearly state your assumptions and complete the question based off these assumptions.\n",
        "\n",
        "5. Be careful as you complete the assignment. There are several text-based questions to be answered in Markdown (text) cells. The questions are accompanied by the ‚ùì emoji. Your answers should be entered in the markdown cells with the üìù emoji.\n",
        "\n",
        "6. Submit your Notebook as a `.ipynb` file that adopts this naming convention: *SYSC4415W23_A2_\\<First Name\\>_\\<Last Name\\>_\\<StudentID\\>.ipynb* on Brightspace. I should be able to run your code without errors.\n",
        "\n",
        "7. Make sure you enable a GPU accelerator (in Runtime > Change runtime type) starting at Part 4 and that your training code uses it. GPU resources are limited, so it is recommended not to use the accelerator for prior steps.\n",
        "\n",
        "8. All plots should be made with matplotlib and labeled properly (ie. include axis labels and legends).\n",
        "\n",
        "## Context\n",
        "\n",
        "It is 2030, and a new RNA virus named SARS-CoV-3 is wreaking havoc across the globe. Its death rate is estimated at 95%, making it one of the deadliest  respiratory viruses known to mankind. Fortunately, an Ottawa-based biotech company developed a nasally-delivered vaccine *Greenraza*‚Ñ¢Ô∏è that can neutralize the virus in living patients. However, administrating the vaccine increases the risk of lung cancer by a whooping 60%. It is therefore vital that the drug be administered to infected patients only, not to patients infected with another respiratory virus such as the common cold or influenza. The virus cannot be detected through blood or breath analyses. It can only be detected by means of x-ray imaging.\n",
        "\n",
        "Having heard of your newly developed expertise in deep learning, you have been tasked by the Ottawa Hospital with the design of a machine learning model capable of distinguishing patients infected with SARS-CoV-3 from patients that have pneumonia and non-infected patients. Healthy patients can be discharged, while patients with pneumonia must be isolated, but without being given *Greenraza*‚Ñ¢Ô∏è."
      ],
      "metadata": {
        "id": "PGuAmMpysXXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project initialization\n",
        "\n",
        "Run the cells below to set-up the notebook (ie. download the dataset) and install the required external libraries."
      ],
      "metadata": {
        "id": "c33I6cJzIn0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS (downloads the dataset)\n",
        "! rm -rf SYSC4415W23_A2_dataset SYSC4415W23_A2_dataset.zip\n",
        "! wget https://github.com/jrgreen7/SYSC4906/releases/download/Assignment2/SYSC4415W23_A2_dataset.zip && unzip SYSC4415W23_A2_dataset.zip"
      ],
      "metadata": {
        "id": "TEbQzpX8j7bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN THIS (installs external libraries)\n",
        "!pip install timm\n",
        "!pip install git+https://github.com/nottombrown/imagenet_stubs\n",
        "!pip install torchstat"
      ],
      "metadata": {
        "id": "NanqafBgkZFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Preparing the dataset\n",
        "\n",
        "The Ottawa Hospital has provided you with a dataset to develop your model. The dataset is available here. The dataset contains a folder containing a spreadsheet with metadata for each image in the dataset and a subfolder containing the 200x200 images (with random filenames)."
      ],
      "metadata": {
        "id": "q1XKrzDrs11o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import read_csv\n",
        "from matplotlib.pyplot import bar, xlabel, ylabel, title"
      ],
      "metadata": {
        "id": "cLf1gprJKQ1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Using pandas' `read_csv` function, load the dataframe containing the image metadata (`dataset_metadata.csv`)."
      ],
      "metadata": {
        "id": "QHTpQfihKSsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads the image metadata into a pandas dataframe\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "1qhfruYusvHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Use the `head` method to print the top five rows of the dataframe."
      ],
      "metadata": {
        "id": "btf3Q-VK_o1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints the top five rows in the dataset\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "SkWvyTpjn8pE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Using pandas' [query method](https://pandas.pydata.org/docs/user_guide/indexing.html#the-query-method) and the `len` methods on the selections, print the number of images in the training, validation and test sets."
      ],
      "metadata": {
        "id": "n-ZA-MdI_zzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints the dimensions of the dataframe\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "ewWdw9Zvx5x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4:** Using the `value_counts` method on the ‚Äúlabel‚Äù column, provide the composition of the dataset in terms of the number of SARS-CoV-3 cases, pneumonia cases and healthy x-rays. In another cell, prepare a bar chart from that data using matplotlib's `bar` method. Note that the result of the `value_counts` methods is a series object whose property `index` is the label."
      ],
      "metadata": {
        "id": "D_cEMcdnwzpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates a breakdown of the images' classes\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "XnNdC4_XxOV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots a bar chart\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "DgEUaXfujlR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ùì ***Question: Is the data balanced or not? If not, specify why class imbalance makes classification more difficult, and suggest one method you could use to deal with the imbalanced data.***"
      ],
      "metadata": {
        "id": "7actPHfExeYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù YOUR ANSWER GOES HERE"
      ],
      "metadata": {
        "id": "6QR5HTn_m9P6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Applying pre-trained CNN models to the data\n",
        "\n",
        "Researchers make pre-trained neural networks available to the community at large. There are many, many pre-trained CNNs available in online repositories that researchers can leverage for their own applications."
      ],
      "metadata": {
        "id": "2gGFYwdHBWvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.io import read_image\n",
        "from timm import create_model\n",
        "from matplotlib.pyplot import imread, imshow\n",
        "from imagenet_stubs.imagenet_2012_labels import label_to_name"
      ],
      "metadata": {
        "id": "vNx-cQJlKCi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Display the image `SYSC4415W23_A2_dataset/training/sarscov3/100_sarscov3.jpg` from the test set. The matplotlib methods `imread` and `imshow` are useful. üòâ"
      ],
      "metadata": {
        "id": "fxQ7F3K6KCvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the image with matplotlib's imread/imshow\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "ckGQkYL6k41-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Load the ImageNet-pretrained InceptionV3 (`inception_v3`) and ResNet50 (`resnet50`) models with `timm` (this was done in Anthony's CIFAR100 tutorial with PyTorch). Use them to predict the class of the image along with the probability (not the logit). The probability is the result of applying the softmax function to the logits.\n",
        "\n",
        "Of course, because the models were pretrained on ImageNet, it will not predict any of the classes that interest us.\n",
        "\n",
        "***Notes:**\n",
        "1. The `read_image` function can convert an image on disk to a tensor.\n",
        "\n",
        "2. The function `label_to_name` that I imported for you converts the index of an ImageNet class to its English name."
      ],
      "metadata": {
        "id": "42hsfWsyBDPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads the image in a Tensor (the method read_image can load the image in a tensor), calls unsqueeze(0) on the tensor to add a dimension and convert its entries to floats using the .float() method\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "yJ49xCUJl_ao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads the InceptionV3 model predicted class along with its probability\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Qy3maVQ9CJag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads the ResNet50 model predicted class along with its probability\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "BP_or0WhEhyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ùì ***Question: What classes are predicted for the two models? Are the models confident? Is it a good thing?***"
      ],
      "metadata": {
        "id": "IBxaFdfdwnpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù YOUR ANSWERS GO HERE"
      ],
      "metadata": {
        "id": "hjw-R-FdxlFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Instantiating the dataloaders to perform fine tuning\n",
        "When working with large image datasets with PyTorch, people often implement a DataLoader to help manage how images are loaded during training. The dataloader can be combined with methods that implement data augmentation by modifying the images with transforms (eg. scaling, rotation, reflection, cropping, etc.). For the most common applications, there are existing data loaders that are perfectly suitable and that users can use instead of defining their own.\n"
      ],
      "metadata": {
        "id": "soeLJWebR8Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "NZROCPrvJ8sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Using the `ImageFolder` strategy to build a dataloader with a batch size of 128 for training. ([This tutorial](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#afterword-torchvision) is most helpful.)\n",
        "\n",
        "You will also want your dataloader for your training set to apply the following data augmentation transforms (documentation available [here](https://pytorch.org/vision/stable/transforms.html)):\n",
        "\n",
        "1. Random rotation between -10 and 10 deg\n",
        "2. Random horizontal flip with 40% probability"
      ],
      "metadata": {
        "id": "U0yxnCVsKiIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates the dataset and dataloader that will be used for training\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Acm52Rn_ayUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2**: Create the dataloaders you will be using for validation and testing. The transform should only convert the images to a tensor. You should not specify a batch size for the test set dataloader."
      ],
      "metadata": {
        "id": "fj5c1hYV8Oxi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates the dataloader that will be used for validation\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "DmGqrtFN6p7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates the dataloader that will be used testing\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "XX-Gkx8iK7XX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Fine-tuning existing CNN architectures\n",
        "\n",
        "The Inception V3 and ResNet50 models you loaded above were trained on ImageNet which is not a medical dataset. In order to leverage these models for our purposes, we need to modify the architecture so that the final classification layer contains an appropriate number of classes and retune the model weights so that the models become suitable for the classification of our x-rays.\n"
      ],
      "metadata": {
        "id": "Xt5LRQ1B8i39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from timm import create_model\n",
        "import time\n",
        "from matplotlib.pyplot import subplots\n",
        "from torch.optim import AdamW\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch import no_grad, Tensor"
      ],
      "metadata": {
        "id": "LN6ZeKE8Lp-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Using `create_model` from the `timm` package, Load the InceptionV3 and ResNet50 models, replacing the final layer with one appropriate for our purpose (recall that we want to classify x-rays of healthy, pneumonia and SARS-CoV-3 patients). Note that the timm library can assist in replacing the final layer (see [Anthony's tutorial](https://github.com/jrgreen7/SYSC4906/blob/master/W2023/Tutorials/CIFAR100_tutorial_WIP.ipynb)). These are your modified models."
      ],
      "metadata": {
        "id": "iTGT-CC5Los5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads the InceptionV3 model and replaces the final classification layer with a new dense layer\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "FyUSzYSk89Hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loads the ResNet50 model and replaces the final classification layer with a new dense layer\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "X0nCkWigU0dN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** In a tutorial with Anthony, you have seen that you can convert a base learning rate to an effective learning rate based on the batch size you have selected using the following heuristic:\n",
        "\n",
        "$$\\eta_{eff} = \\frac{B\\eta_{base}}{256}$$\n",
        "\n",
        "where $\\eta$ is the learning rate and $B$ is the batch size.\n",
        "\n",
        "Train the final layer modified InceptionV3 and ResNet50 models on your training set. Use the **base** learning rate $\\eta_{base}$ of 0.0005.\n",
        "\n",
        "Use the following settings:\n",
        "\n",
        "**Epochs:** 25\n",
        "\n",
        "**Optimizer:** AdamW\n",
        "\n",
        "**Loss function:** Cross-entropy (it is not required here, but note that using the weight parameter here could help deal with class imbalance)\n",
        "\n",
        "Implement the training loop yourself. Do not use a package that automates the process. Anthony has demonstrated how to do this and much can be taken from [his example](https://github.com/jrgreen7/SYSC4906/blob/master/W2023/Tutorials/CIFAR100_tutorial_WIP.ipynb).\n",
        "\n",
        "‚ùó**Important: Make sure you are using a colab gpu and to store the mean training and validation performance/loss at each epoch as you will be plotting them in the next steps.**"
      ],
      "metadata": {
        "id": "fnPggZay-S_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Moves the modified inceptionV3 model to GPU\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Xpt117nYLyPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiates the optimizer for the modified InceptionV3 model using the specified effective learning rate\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "xPG5MGPIMk4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets up the loss function for the modified InceptionV3 model\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "EfcMH2x-Mpjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tunes the weights in the final layer the modified InceptionV3 model (main learning loop)\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "D8tIT-9M-WkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Moves the modified ResNet50 model to GPU\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "O4OZyXmHxkFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiates the optimizer for the modified ResNet50 model\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Fz_V6au6RbV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sets up the loss function for the modified ResNet50 model\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "W3iE55k-RbV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tunes the weights in the final layer the modified ResNet50 model (main learning loop)\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "HOecqyEUFpnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** In different labeled subplots, display the learning curves for each model. Each subplot should display loss on the training set and the validation set (*i.e.* 2 curves per subplot). Use matplotlib."
      ],
      "metadata": {
        "id": "hWdTW9APDrpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Displays the learning curves (loss) for both models in two separate subplots\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "l-uQC4sIX6-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ùì ***Question: Comment on your learning curves. What do they tell you?***"
      ],
      "metadata": {
        "id": "EvoZe_IGQJ__"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù YOUR ANSWER GOES HERE"
      ],
      "metadata": {
        "id": "UTgGmtFzQVu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Performance evaluation on a test set\n",
        "\n",
        "Of course, estimating the performance of your model on unseen data is a key step in machine learning methodology. Here, you will summarize model performance for your InceptionV3 model and ResNet50 model on the test set."
      ],
      "metadata": {
        "id": "GBAcg-ezIKZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "from torch import no_grad"
      ],
      "metadata": {
        "id": "qfL6yr-E32SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1:** Iterate through the images in the test set using the test dataloader to make predictions for the test set images and retrieve their actual label (its index). Note that this is done in a way similar to the validation step in the training loop.\n",
        "\n",
        "Append the predicted class index to a list, the actual labels to another and the probability of the SARS-CoV-3 class to another list.\n",
        "\n",
        "Do this for both fine-tuned models.\n",
        "\n",
        "Note that the indices map to the classes as follows:\n",
        "\n",
        "0: normal\n",
        "\n",
        "1: pneumonia\n",
        "\n",
        "2: sarscov3"
      ],
      "metadata": {
        "id": "yfskXdis0a8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a list of predictions, a list of actual labels and a list of probabilities of the SARS-CoV-3 class for the fine-tuned InceptionV3 model applied to the test set\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "euMGErLf0i_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates a list of predictions, a list of actual labels and a list of probabilities of the SARS-CoV-3 class for the fine-tuned ResNet50 model applied to the test set\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "e6UMYl4W3FhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2:** Show the confusion matrices for both models. The `confusion_matrix` function from scikit-learn I imported for you is useful for this."
      ],
      "metadata": {
        "id": "xl53hgxEE6PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates the confusion matrix for the modified InceptionV3 model\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "Ya11twapResF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates the confusion matrix for the modified ResNet50 model\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "ns6s6QGz4YIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ùì ***Question: Based off these matrices, report the accuracy of the models.***"
      ],
      "metadata": {
        "id": "5g_NVIx5RpOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù YOUR ANSWER GOES HERE"
      ],
      "metadata": {
        "id": "trfucb7V53fR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3:** Use the `PrecisionRecallDisplay.from_predictions` methods documented [here](https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html#:~:text=The%20precision%2Drecall%20curve%20shows,a%20low%20false%20negative%20rate.) to plot the precision recall curves for your models. There are three classes, so convert your labels so that it becomes a binary classification scenario, ie. SARS-CoV-3 vs. not-SARS-CoV-3."
      ],
      "metadata": {
        "id": "7umfab-rFaOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plots the PR curves of your fine-tuned InceptionV3 and ResNet50 models \n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "xKoSmJAJRe6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚ùì ***Question: Based off the results you obtained in this section, which model performs best? Why do you think (in 5 sentences or less)?***"
      ],
      "metadata": {
        "id": "CUHNYRuIylfQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù YOUR ANSWER GOES HERE"
      ],
      "metadata": {
        "id": "s8m6O95LylqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Answering questions from investors ‚ùì\n",
        "\n",
        "Bfizer has heard about your model and are interested in investing in your technology. However, before they engage in further discussions, they want you to answer the following questions:\n",
        "\n",
        "1. Briefly provide techniques that you would explore next to further improve the performance of your model?\n",
        "\n",
        "2. A competitor has trained an SVM on the same dataset but performs worse than your model. Why do CNNs perform better than SVM for image classification? Discuss two aspects: differences in features and differences in training data.\n",
        "\n",
        "3. The investors consider investing in a very small device that can run your model. Would your best model fit on this small cost-effective device with 32 MB of storage, assuming that all parameters in the model are 16 bit floats (you can ignore everything in the model but the trainable parameters)? You can use the `torchstat` library ([link](https://github.com/Swall0w/torchstat)) to get the number of parameters. Note that the relevant function from this library was already imported for you (below).\n",
        "\n",
        "4. If your best model predict a positive SARS-CoV-3 case, how likely is it that you are correct? How likely is it that you are wrong?\n",
        "\n",
        "5. Assuming that the test data is representative of the disease status among the general population of Canada (it is not, why? hint: think of bias.), how many Canadians (Canada pop: 38M) currently have SARS-CoV-4? How much will it cost Canadians to inject all infected people if one dose of Greenraza‚Ñ¢Ô∏è can be purchased for 13 CAD (Canadian Dollars)? How many people have pneumonia and need to be isolated? (Show your calculations.)\n",
        "\n",
        "**Note: Your confusion matrices might be useful for the last 2 questions. üòâ**"
      ],
      "metadata": {
        "id": "1dfWbPP0HpnR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üìù YOUR SHORT ANSWERS GO HERE (add code cells below as needed for calculations, eg. for running the `stat` function from the `torchstat` package)"
      ],
      "metadata": {
        "id": "mcIuatctITLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determines the number of trainable parameters in your best model\n",
        "from torchstat import stat\n",
        "\n",
        "# YOUR CODE HERE"
      ],
      "metadata": {
        "id": "CozarykaTi5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See? It wasn't that hard, was it?! üòâ"
      ],
      "metadata": {
        "id": "2cN1EF53Xj9Q"
      }
    }
  ]
}