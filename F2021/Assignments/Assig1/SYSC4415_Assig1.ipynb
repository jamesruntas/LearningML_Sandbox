{"nbformat":4,"nbformat_minor":2,"metadata":{"colab":{"name":"SYSC4415_Assig1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# SYSC4415 Introduction to Machine Learning Answer Key\n","## Assignment 1\n","|**Student name** | **Student number**|\n","|-----------------|-------------------|\n","| TBC|TBC  |"],"metadata":{"id":"jDOT_bqlnuaL"}},{"cell_type":"markdown","source":["# Question 1\n"," > i) Calculate the gradient of the following function: \n","$$ f(x,y,z) \\stackrel{\\text{def}}{=} z^3 + x^2y-y^2 + 3yz $$\n","\n",">  ii) What is the gradient at (-2,3,1) \n","\n",">  iii)What does this vector represent?"],"metadata":{"id":"hq842SciP6bK"}},{"cell_type":"markdown","source":["..."],"metadata":{"id":"rXV6T_R8QM4l"}},{"cell_type":"markdown","source":["# Question 2\n","*(see text of question in assignment instructions)*\n","\n",">a.   What is the expected value from this sample? Using an unbiased estimator, what is the sample variance and standard deviation?\n","\n",">b.   What is $Pr(3)$?\n","\n",">c.   Find the expected value and the variance for $Pr(x)$.\n","\n",">d.   Find the probability that a student slept 2 hours the night before ($x=2$), given that they did not need excess amounts of coffee. That is, find $Pr(2|-)$. Hint: $Pr(+)$ can be found by summing over $Pr(+|x)Pr(x)$, for all $x$. $Pr(-|x)$ can be derived from $Pr(+|x)$."],"metadata":{"id":"ayyHKf2kACcr"}},{"cell_type":"markdown","source":["..."],"metadata":{"id":"Yk_Y2zMzlo2a"}},{"cell_type":"markdown","source":["#Question 3\n","\n","Create a python notebook which loads the Kaggle Diabetes dataset (https://www.kaggle.com/mathchi/diabetes-data-set). This dataset has 8 features and 2 classes of diabetes possibility: Outcome: 0= doesnt't have diabetes; 1= has diabetes. *Hint: look at the notebooks from Tutorials 2 & 3 for example code for achieving the steps below.* \n","\n",">  a) Split the data, using 75% for training and 25% for test. Make sure you use stratified sampling. \n","\n",">  b) Train and test a logistic regression classifier. How accurate is your classifier?\n","\n",">  c) Repeat part b), only the Pregnancies and SkinThickness features from the dataset. Was the classifier accuracy impacted?\n","  \n",">  d) Using the (two feature) classifier from part c), create two subplots using the Preganancies and SkinThickness features from the dataset.\n","\n",">> i)  On the first, plot the decision boundary and the training data. Use green for doesn't have diabetes (Outcome==0) and blue for Has diabetes (Outcome==1).\n","\n",">> ii) On the second, plot the decision boundary and the test data. Use the same colours (blue/green), but highlight all misclassified test points (from either class) in red.\n","\n","\n"],"metadata":{"id":"F476OY19yL8C"}},{"cell_type":"code","execution_count":1,"source":["# Load libraries..."],"outputs":[],"metadata":{"id":"d1-XuzEdo4ts","executionInfo":{"status":"ok","timestamp":1631811316371,"user_tz":240,"elapsed":12,"user":{"displayName":"Victoria Ajila","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03727961744353051498"}}}},{"cell_type":"markdown","source":["## Q3.a) Create the dataset\n","\n","The first step is loading the Kaggle Diabetes data. We will then split off the test data to be used for all training sets. Then create each training set, using **stratified sampling**"],"metadata":{"id":"eCZnsSnbybUQ"}},{"cell_type":"code","execution_count":3,"source":["# Load the Kaggle Diabetes dataset\n","kaggleData =\n"],"outputs":[],"metadata":{"id":"3id7ezjlsn-J","executionInfo":{"status":"ok","timestamp":1631811328970,"user_tz":240,"elapsed":417,"user":{"displayName":"Victoria Ajila","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03727961744353051498"}}}},{"cell_type":"markdown","source":["# Question 4\n","\n","Linear regression. Download the file “Assig1Q4.csv” from GitHub under “Assignments/Assignment1”. The first column represents the X values, while the second column represents the Y values.\n","\n",">  a) Plot the data\n","\n","We are going to use linear regression to fit a linear and a cubic model to these data.\n","\n",">  b) Without using sklearn.linear_model (or any other linear regression libraries), write your own python code to implement the least squares solution for linear regression. That is:\n","$$\\beta=(X^TX)^{−1}X^Ty$$\n","\n",">  c) Assuming the model $y=mx+b$, use your code to best-fit the parameters $m$ and $b$ to the data. Report your optimal parameter values. \n","Hints: \n","  * recall that you must create the ‘augmented’ feature vector $X$ from the given $x$ data (add a column of 1’s). \n","  * look at numpy.T(), numpy.matmul(), numpy.dot(), and numpy.linalg.inv()\n","\n","\n",">  d) Plot your line of best fit on top of the data\n","\n",">  e) Calculate the sum of square residuals, or mean squared error, as in:\n","\n","$$MSE(\\beta) = \\sum_{i=1}^{N}{(y−X\\beta)^2}$$\n",">  f) Assuming the model $y=ax^3+bx^2+cx+d$, repeat steps b-e using this new \n","  model (i.e. estimate the optimal values for $a$,$b$,$c$,$d$; report those estimates; plot the line of best fit; report the MSE).\n","\n",">  g) Briefly discuss which model would you prefer for these data?\n","\n",">  h) Why is best-fitting the second (cubic) model still considered linear regression?\n","\n"],"metadata":{"id":"E5UPspGuGNga"}},{"cell_type":"markdown","source":["## Step 1: Load the CSV file"],"metadata":{"id":"6EnFpwBiY5i4"}},{"cell_type":"code","execution_count":4,"source":["import pandas as pd\n","data = pd.read_csv(\"Assig1Q4.csv\", header=None)"],"outputs":[],"metadata":{"id":"VVGXLK2HZCQ6","executionInfo":{"status":"ok","timestamp":1631811337570,"user_tz":240,"elapsed":241,"user":{"displayName":"Victoria Ajila","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03727961744353051498"}}}},{"cell_type":"markdown","source":["## Step 2: Linear model $y=mx+b$"],"metadata":{"id":"L-EMZyfAb89b"}},{"cell_type":"code","execution_count":5,"source":["\n","# Augment the x vector\n","\n","# Compute beta\n","\n","# Compute the MSE\n","\n","print(\"MSE =\", MSE)"],"outputs":[],"metadata":{"id":"qVf8TwYMbx70","executionInfo":{"status":"ok","timestamp":1631811343281,"user_tz":240,"elapsed":158,"user":{"displayName":"Victoria Ajila","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03727961744353051498"}}}},{"cell_type":"markdown","source":["## Step 3: Cubic model $y=ax^3+bx^2+cx+d$"],"metadata":{"id":"RRN5Hhncge8y"}},{"cell_type":"code","execution_count":6,"source":["# Augment the x vector\n","\n","# Compute beta\n","\n","# Compute the MSE\n","\n","print(\"MSE =\", MSE_quad)"],"outputs":[],"metadata":{"id":"rZWNuz5tge80","executionInfo":{"status":"ok","timestamp":1631811348521,"user_tz":240,"elapsed":163,"user":{"displayName":"Victoria Ajila","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03727961744353051498"}}}},{"cell_type":"markdown","source":["# Question 5\n","\n","- Create a Jupyter Notebook based on `Tutorial-3_ComparingMultipleClassifiers.ipynb` to use `make_classification` to create a linearly separable dataset, with 2 classes, 2 informative features, 1500 samples per class, using a class_sep=1.7, and a random_state of 5. \n","- Generate some random noise of the same shape as your feature data, drawn from a standard normal distribution (see `numpy.random`) and a random_state of 5. \n","- Create four datasets: \n","    1. no noise, \n","    2. data + 0.5 * noise, \n","    3. data + 1.0 * noise, \n","    4. data + 2.0 * noise. \n","\n","> a) For all four datasets, plot the data, labelling each (sub)plot by the degree of noise added (i.e. 0, 0.5, 1.0, and 2.0)\n","\n","> b) For each dataset, create training and test data using a 70/30 train/test split (see train_test_split).\n","\n","> c) For each dataset, train and test an SVM classifier with a polynomial kernel with `degree=2`, and `C=1.0`. Report the test score for each. How does prediction accuracy change with noise level?\n","\n","> d) For a noise level of 0.5, train and test SVM classifiers using the following values for $C: \\{0.001, 0.01, 0.1, 1, 10, 100\\}$. \n","   - Report the test accuracy for each. \n","   - How does performance vary with $C$?\n","   - Briefly describe what the $C$ controls for sklearn.svc. *Hint: look at the documentation for `sklearn.svc` rather than the class notes here...*\n"],"metadata":{"id":"NQMvagUYykXa"}},{"cell_type":"code","execution_count":7,"source":["# Load the required libraries...\n"],"outputs":[],"metadata":{"id":"gYZYt5NmSvzm","executionInfo":{"status":"ok","timestamp":1631811493529,"user_tz":240,"elapsed":155,"user":{"displayName":"Victoria Ajila","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03727961744353051498"}}}}]}